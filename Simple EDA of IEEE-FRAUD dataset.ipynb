{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 본 커널은 아래 커널들을 참고했습니다. \n",
    "    - https://www.kaggle.com/robikscube/ieee-fraud-detection-first-look-and-eda\n",
    "\n",
    "## 데이터셋 임포트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/mouradmourafiq/pandas-summary\n",
    "!pip install pandas-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_summary import DataFrameSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os, timeit, datetime\n",
    "\n",
    "pd.set_option('display.max_columns', 400)\n",
    "\n",
    "# for local execution\n",
    "current_dir = os.path.abspath('.')\n",
    "dataset_dir = os.path.join(os.path.abspath(current_dir + \"/../\"), 'dataset_kaggle_IEEE_CIS_Fraud_Detection')\n",
    "print(os.listdir(dataset_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 데이터 로딩(for Kaggle Kernel)\n",
    "# train_tran = pd.read_csv('../input/train_transaction.csv', index_col='TransactionID')\n",
    "# train_iden = pd.read_csv('../input/train_identity.csv', index_col='TransactionID')\n",
    "# test_tran = pd.read_csv('../input/test_transaction.csv', index_col='TransactionID')\n",
    "# test_iden = pd.read_csv('../input/test_identity.csv', index_col='TransactionID')\n",
    "# sample_sub = pd.read_csv('../input/sample_submission.csv', index_col='TransactionID')\n",
    "\n",
    "# 데이터 로딩 (for local execution)\n",
    "train_tran = pd.read_csv(os.path.join(dataset_dir, 'train_transaction.csv'))\n",
    "train_iden = pd.read_csv(os.path.join(dataset_dir, 'train_identity.csv'))\n",
    "test_tran = pd.read_csv(os.path.join(dataset_dir, 'test_transaction.csv'))\n",
    "test_iden = pd.read_csv(os.path.join(dataset_dir, 'test_identity.csv'))\n",
    "sample_sub = pd.read_csv(os.path.join(dataset_dir, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dfs = DataFrameSummary(train_tran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dfs.columns_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dfs.columns_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train과 Test 데이터는 모두 각각 Identity와 Transaction 두 개의 .csv파일로 나뉘어 있습니다. 이는 'TransactionID'라는 column으로 join되어 있습니다. 단, `train_identity.csv`와 `train_transaction.csv`의 모든 거래 내역(transactions)들이 서로 완벽히 일치하지는 않습니다. \n",
    "\n",
    "* <b>`train_transaction.csv`의 범주형 번수</b>\n",
    "    * TransactionID : reference datetime(실제 timestamp와 다름)으로부터의 timedelta(시간변화량)을 의미\n",
    "    * TransactionAmt : USD를 이용해 지불된 거래 금액\n",
    "    * ProductCD : 제품 code(각 거래마다의 제품 코드)\n",
    "    * card1 ~ card6 : 거래에 사용한 카드 정보(카드 타입, 카드 카테고리, 카드 발행은행, 국가 등)\n",
    "    * addr1 ~ addr2 : 주소\n",
    "    * dist : 거리(distance)\n",
    "    * P_emaildomain, R_emaildomain : 구매자 및 수신자 이메일 도메인 주소\n",
    "    * C1 ~ C14 : 얼마나 많은 주소가 지불 카드와 관련있는지에 대한 횟수(counting)로, 실제 의미는 비식별 처리되어(masked)있음.\n",
    "    * D1 ~ D15 : 이전 거래일과의 시간변화량(timedelta)\n",
    "    * M1 ~ M9 : 카드에 적힌 이름이나 주소 등등이 일치하는지 여부\n",
    "\n",
    "\n",
    "* <b>`train_identity.csv`의 범주형 변수</b>\n",
    "    * DeviceType\n",
    "    * DeviceInfo\n",
    "    * id_12 ~ id_38 : 트랜잭션과 관련된 식별 정보 (네트워크 연결 정보 - IP, ISP, Proxy 등) 및 디지털 서명(UA/browser/OS/version 등)을 의미하며, Vesta의 사기 방지 시스템 및 디지털 보안 파트너사가 함께 수집했습니다. 필드의 이름들은 개인정보 보호를 위해 비식별 처리되어 있습니다. \n",
    "   \n",
    "이번 대회의 데이터는 메모리 문제를 유발할 수 있기 때문에, Memory reduce를 진행하여야 합니다. 불러오는 것은 물론 처리에도 시간이 많이 소비되므로, 메모리 사용량을 줄여 보겠습니다. 이번 대회의 데이터 타입들은 대부분 int64, float64로 이루어져 있으며, 실제 데이터는 int64 타입이지만 실질적인 데이터 범위가 int16에만 속한다면 메모리를 줄이는 것이 효율적일 것입니다. (https://hwiyong.tistory.com/238 참고)\n",
    "\n",
    "\n",
    "#### 데이터셋의 메모리 줄이기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Dataframe의 메모리 사이즈를 줄이기 위한 함수\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "## REducing memory\n",
    "train_tran = reduce_mem_usage(train_tran)\n",
    "train_iden = reduce_mem_usage(train_iden)\n",
    "test_tran = reduce_mem_usage(test_tran)\n",
    "test_iden = reduce_mem_usage(test_iden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tran.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_tran.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iden.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_iden.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data \n",
    "첫번째로 Train과 Test 데이터에 대한 time series 분할을 해볼 것입니다. `TransactionDT` feature는 주어진 참조 시간(reference datetime, 현실의 시간과 다름)에 대한 시간 변화량(timedelta)입니다. train과 test 데이터가 시간에 따라 분리되어 있으며, 두 데이터셋 사이에 약간 간격이 존재하는 것을 확인할 수 있습니다. 이는 추후 CV(Cross validation)기법을 사용해야 하는지에 대한 여부 결정에 영향을 미칩니다. 이제 다른 train, test의 feature들에 대해서도 분석해 보겠습니다.\n",
    "\n",
    "### train_transaction.csv의 정수형 데이터 피쳐들 살펴보기\n",
    "#### Training set에 들어 있는 Target의 분포 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tran.groupby('isFraud') \\\n",
    "    .count()['TransactionID'] \\\n",
    "    .plot(kind='barh',\n",
    "          title='Distribution of Target in Train',\n",
    "          figsize=(15, 3))\n",
    "plt.show()\n",
    "\n",
    "print('train_tran.df안에 존재하는 사기 거래의 비율 : ', train_tran['isFraud'].mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 거래금액(`TransactionAmt`)의 분산 확인해보기\n",
    "매우 큰 트랜잭션이 전체를 흔드는 것을 방지하기 위해 log 정규화를 수행한 후 plot을 그려 봅니다. 로그로 변환하는 과정 때문에 0~1 사이의 모든 값은 음수로 표시됩니다.\n",
    "이제 정상 거래와 사기 거래에 대해서도 plot을 그려 보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 6))\n",
    "train_tran.loc[train_tran['isFraud'] == 1] \\\n",
    "    ['TransactionAmt'].apply(np.log) \\\n",
    "    .plot(kind='hist',\n",
    "          bins=100,\n",
    "          title='Log Transaction Amt - Fraud',\n",
    "          xlim=(-3, 10),\n",
    "         ax= ax1)\n",
    "train_tran.loc[train_tran['isFraud'] == 0] \\\n",
    "    ['TransactionAmt'].apply(np.log) \\\n",
    "    .plot(kind='hist',\n",
    "          bins=100,\n",
    "          title='Log Transaction Amt - Not Fraud',\n",
    "          xlim=(-3, 10),\n",
    "         ax=ax2)\n",
    "train_tran.loc[train_tran['isFraud'] == 1] \\\n",
    "    ['TransactionAmt'] \\\n",
    "    .plot(kind='hist',\n",
    "          bins=100,\n",
    "          title='Transaction Amt - Fraud',\n",
    "         ax= ax3)\n",
    "train_tran.loc[train_tran['isFraud'] == 0] \\\n",
    "    ['TransactionAmt'] \\\n",
    "    .plot(kind='hist',\n",
    "          bins=100,\n",
    "          title='Transaction Amt - Not Fraud',\n",
    "         ax=ax4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사기 거래는 평균 거래 금액이 더 높아 보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `TransactionDT` feature로 시간변화에 따른 분포 확인해보기\n",
    "\n",
    "아래에서 볼 수 있듯 trian_tran과 test_tran간에는 약간의 시간 간격이 벌어져 있습니다. 이는 추후 cross validation을 해야 할지 말지에 영향을 미칩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_tran['TransactionDT'].plot(kind='hist',\n",
    "                                        figsize=(15, 5),\n",
    "                                        label='train',\n",
    "                                        bins=50,\n",
    "                                        title='Train vs Test TransactionDT distribution')\n",
    "test_tran['TransactionDT'].plot(kind='hist',\n",
    "                                       label='test',\n",
    "                                       bins=50)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_transaction.csv의 `ProductCD` 찍어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tran.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProductCD의 관측 횟수\n",
    "train_tran.groupby('ProductCD') \\\n",
    "    ['TransactionID'].count() \\\n",
    "    .sort_index() \\\n",
    "    .plot(kind='barh',\n",
    "          figsize=(15, 3),\n",
    "         title='Count of Observations by ProductCD')\n",
    "plt.show()\n",
    "\n",
    "# ProductCD별 사기의 비율\n",
    "train_tran.groupby('ProductCD')['isFraud'] \\\n",
    "    .mean() \\\n",
    "    .sort_index() \\\n",
    "    .plot(kind='barh',\n",
    "          figsize=(15, 3),\n",
    "         title='Percentage of Fraud by ProductCD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유독 'C' 코드가 사기 비중이 높습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_transaction.csv의 카테고리형 피쳐들 살펴보기\n",
    "#### `card1`~`card6` 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_cols = [c for c in train_tran.columns if 'card' in c]\n",
    "train_tran[card_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_idx = 0\n",
    "for c in card_cols:\n",
    "    if train_tran[c].dtype in ['float64','int64']:\n",
    "        train_tran[c].plot(kind='hist',\n",
    "                                      title=c,\n",
    "                                      bins=50,\n",
    "                                      figsize=(15, 2),\n",
    "                                      color=color_pal[color_idx])\n",
    "    color_idx += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction_fr = train_tran.loc[train_tran['isFraud'] == 1]\n",
    "train_transaction_nofr = train_tran.loc[train_tran['isFraud'] == 0]\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 8))\n",
    "\n",
    "train_transaction_fr.groupby('card4')['card4'].count().plot(kind='barh', ax=ax1, title='Count of card4 fraud')\n",
    "train_transaction_nofr.groupby('card4')['card4'].count().plot(kind='barh', ax=ax2, title='Count of card4 non-fraud')\n",
    "train_transaction_fr.groupby('card6')['card6'].count().plot(kind='barh', ax=ax3, title='Count of card6 fraud')\n",
    "train_transaction_nofr.groupby('card6')['card6'].count().plot(kind='barh', ax=ax4, title='Count of card6 non-fraud')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `TransactionDT`와 `card`~`card6`을 groupby해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 올바른 card_id만 남기고 나머지는 쓰레기값으로 대체\n",
    "def corret_card_id(x): \n",
    "    x=x.replace('.0','')\n",
    "    x=x.replace('-999','nan')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransactionDT를 date로 변환하고 새로운 column 추가\n",
    "def definie_indexes(df):\n",
    "    \n",
    "    # date column 추가\n",
    "    START_DATE = '2017-12-01'\n",
    "    startdate = datetime.datetime.strptime(START_DATE, '%Y-%m-%d')\n",
    "    df['date'] = df['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds = x)))\n",
    "    \n",
    "    # create card ID \n",
    "    cards_cols= ['card1', 'card2', 'card3', 'card5']\n",
    "    for card in cards_cols: \n",
    "        if '1' in card: \n",
    "            df['Card_ID']= df[card].map(str)\n",
    "        else : \n",
    "            df['Card_ID']+= ' '+df[card].map(str)\n",
    "    \n",
    "    # sort train data by Card_ID and then by transaction date \n",
    "    df= df.sort_values(['Card_ID', 'date'], ascending=[True, True])\n",
    "    \n",
    "    # small correction of the Card_ID\n",
    "    df['Card_ID']=df['Card_ID'].apply(corret_card_id)\n",
    "    \n",
    "    # set indexes \n",
    "    df= df.set_index(['Card_ID', 'date'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date column을 추가하여 기존의 train_tran 덮어쓰기\n",
    "with timer('define real IDs...'):\n",
    "    train_tran = definie_indexes(train_tran)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `add1`~`addr2` 살펴보기\n",
    "`dist` feature는 단순 거리이므로 따로 분석하지 않았습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NA값 체크하기\n",
    "print(' addr1 - has {} NA values'.format(train_tran['addr1'].isna().sum()))\n",
    "print(' addr2 - has {} NA values'.format(train_tran['addr2'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tran['addr1'].plot(kind='hist', bins=500, figsize=(15, 2), title='addr1 distribution')\n",
    "plt.show()\n",
    "train_tran['addr2'].plot(kind='hist', bins=500, figsize=(15, 2), title='addr2 distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `P_emaildomain`과 `R_emaildomain` feature 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(18, 12))\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "p_email = sns.countplot(y='P_emaildomain', data=train_tran, ax=axes[0])\n",
    "r_email = sns.countplot(y='R_emaildomain', data=train_tran, ax=axes[1])\n",
    "plt.tight_layout()\n",
    "\n",
    "# 유니크한 이메일 주소의 개수\n",
    "print('Count of Unique P_emaildomain : ', train_tran.P_emaildomain.nunique()) # 59 unique domains\n",
    "print('Count of Unique R_emaildomain : ', train_tran.R_emaildomain.nunique()) # 59 unique domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gmail, Outlook, Yahoo 등의 이메일 도메인이 상위권에 올라 있지만 특이하게 anonymous.com이 눈에 띕니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `c1`~`c14` 살펴보기\n",
    "c1~c14는 숫자로 된 열들이므로 pairplot을 그려 보도록 합니다. pairplot을 그려 보는 것은 특정 feature가 다른 feature과 차이가 있을 경우 유용한 방법입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_cols = [c for c in train_tran if c[0] == 'C']\n",
    "print(train_tran[c_cols].head())\n",
    "\n",
    "# 500개의 사기 및 정상 거래를 샘플링해 그래프를 그립니다.\n",
    "sampled_train = pd.concat([train_tran.loc[train_tran['isFraud'] == 0].sample(500),\n",
    "          train_tran.loc[train_tran['isFraud'] == 1].sample(500)])\n",
    "\n",
    "sns.pairplot(sampled_train, \n",
    "             hue='isFraud',\n",
    "            vars=c_cols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `D1`~`D9` features에 대해서도 그래프 그려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_cols = [c for c in train_tran if c[0] == 'D']\n",
    "print(train_tran[d_cols].head())\n",
    "\n",
    "sns.pairplot(sampled_train, \n",
    "             hue='isFraud',\n",
    "            vars=d_cols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `M1`~`M9` feature 살펴보기\n",
    "`M1`~`M9`는 T, F, NaN값을 갖고 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cols = [c for c in train_tran if c[0] == 'M']\n",
    "print(train_tran[m_cols].head())\n",
    "\n",
    "(train_tran[m_cols] == 'T').sum().plot(kind='bar',\n",
    "                                              title='Count of T by M column',\n",
    "                                              figsize=(15, 2))\n",
    "plt.show()\n",
    "(train_tran[m_cols] == 'F').sum().plot(kind='bar',\n",
    "                                              title='Count of F by M column',\n",
    "                                              figsize=(15, 2))\n",
    "plt.show()\n",
    "(train_tran[m_cols].isna()).sum().plot(kind='bar',\n",
    "                                              title='Count of NaN by M column',\n",
    "                                              figsize=(15, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`M0`과 `M4` column이 문제가 있음을 확인할 수 있습니다\n",
    "\n",
    "#### `V1`~`V339` 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_cols = [c for c in train_tran if c[0] == 'V']\n",
    "print(train_tran[v_cols].head())\n",
    "\n",
    "train_tran.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tran.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iden.info()\n",
    "train_iden.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프를 그리기 위해 v_mean column 추가하기\n",
    "train_tran['v_mean'] = train_tran[v_cols].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(15, 6))\n",
    "train_tran.loc[train_tran['isFraud'] == 1]['v_mean'] \\\n",
    "    .apply(np.log) \\\n",
    "    .plot(kind='hist',\n",
    "          bins=100,\n",
    "          title='log transformed mean of V columns - Fraud',\n",
    "          ax=ax1)\n",
    "train_tran.loc[train_tran['isFraud'] == 0]['v_mean'] \\\n",
    "    .apply(np.log) \\\n",
    "    .plot(kind='hist',\n",
    "          bins=100,\n",
    "          title='log transformed mean of V columns - Not Fraud',\n",
    "          ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_identity.csv 분석하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_identity.csv의 `DeviceInfo` plot 그려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeviceCount, DeviceInfo 두 개의 열을 갖는 DF를 만듭니다.\n",
    "group = pd.DataFrame()\n",
    "group['DeviceCount'] = train_iden.groupby(['DeviceInfo'])['DeviceInfo'].count()\n",
    "group['DeviceInfo'] = group.index\n",
    "\n",
    "# top 30개 Device들에 대해 sort합니다. \n",
    "group_top = group.sort_values(by='DeviceCount',ascending=False).head(30)\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "sns.set(color_codes=True)\n",
    "sns.set(font_scale = 1.3)\n",
    "ax = sns.barplot(x=\"DeviceInfo\", y=\"DeviceCount\", data=group_top)\n",
    "xt = plt.xticks(rotation=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1등이 Windows, 2등이 IOS Device, 3등이 MacOS인것을 확인할 수 있습니다. 또한 주로 desktop에서 결제를 하는 것으로 보입니다. 이제 운영체제별 사기율을 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset dataframe\n",
    "fraud = pd.DataFrame()\n",
    "is_fraud = train_iden[train_tran['isFraud']==1]\n",
    "fraud['DeviceCount'] = is_fraud.groupby(['DeviceInfo'])['DeviceInfo'].count()\n",
    "fraud['DeviceInfo'] = fraud.index\n",
    "\n",
    "# There are too many Devices, so we will subset the top 20\n",
    "group_top = fraud.sort_values(by='DeviceCount',ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "sns.set(color_codes=True)\n",
    "sns.set(font_scale = 1.3)\n",
    "ax = sns.barplot(x=\"DeviceInfo\", y=\"DeviceCount\", data=group_top)\n",
    "\n",
    "font_size= {'size': 'x-large'}\n",
    "ax.set_title(\"Fraud transactions by OS\", **font_size)\n",
    "xt = plt.xticks(rotation=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그래프와 크게 다르지는 않습니다. 순서대로 Windows, IOS 순으로 사기 거래가 잦습니다. 특히 Windows OS에서 그 비중이 높은 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DeviceType` 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사기여부와 함께 DeviceType feature 분석을 위해 `isFraud` column 추가\n",
    "train_identity_ = train_iden.merge(train_tran[['TransactionID', 'TransactionDT', 'isFraud']], \n",
    "                                   on=['TransactionID'])\n",
    "test_identity_ = test_iden.merge(test_tran[['TransactionID', 'TransactionDT']], \n",
    "                                 on=['TransactionID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identity_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_identity_.groupby('DeviceType') \\\n",
    "    .mean()['isFraud'] \\\n",
    "    .sort_values() \\\n",
    "    .plot(kind='barh',\n",
    "          figsize=(15, 5),\n",
    "          title='Percentage of Fraud by Device Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사기 거래의 비율은 mobile에서 더 높은 것을 알 수 있습니다.\n",
    "\n",
    "#### `id01`~`id_38` 분석해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploration id_12 - id_38\n",
    "id01_loc = train_iden.columns.get_loc(\"id_01\")\n",
    "id38_loc = train_iden.columns.get_loc(\"id_38\")\n",
    "df_id = train_iden.iloc[id01_loc:id38_loc+1] #subset dataframe id12-id19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id.dtypes # id features의 데이터 타입 모두 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`id` features에는 다양한 데이터 타입이 섞여 있으며, 대부분 NaN값을 갖고 있습니다. `id_30`은 운영체제이고, `id_31`은 사용하는 웹 브라우저, `id_33`은 기기 해상도를 나타내는 것으로 보입니다. `id_30`과 `id_31`을 자세히 살펴 보도록 합시다.\n",
    "\n",
    "#### `id_30` 그려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a dataframe with 2 cols: device info and the count by device\n",
    "group_id30 = pd.DataFrame()\n",
    "group_id30['id_30Count'] = df_id.groupby(['id_30'])['id_30'].count()\n",
    "group_id30['id_30'] = group_id30.index\n",
    "\n",
    "# There are too many addr, so we will subset the top 20\n",
    "group_top_id30 = group_id30.sort_values(by='id_30Count',ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "sns.set(color_codes=True)\n",
    "sns.set(font_scale = 1.3)\n",
    "ax = sns.barplot(x=\"id_30\", y=\"id_30Count\", data=group_top_id30)\n",
    "xt = plt.xticks(rotation=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "거래는 Windows 10, IOS 11.2.2, Android 7.0 순으로 많이 이루어졌습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 운영체제, 브라우저별 사기율을 보기 위해 isFraud column 추가\n",
    "group_id = train_iden.merge(train_tran[['TransactionID', 'isFraud']], \n",
    "                                 on=['TransactionID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id.groupby('id_30') \\\n",
    "    .mean()['isFraud'] \\\n",
    "    .sort_values() \\\n",
    "    .plot(kind='barh',\n",
    "          figsize=(15, 25),\n",
    "          title='Percentage of Fraud by OS Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(featured) 기타 및 구형 안드로이드 OS에서 유독 사기 거래의 비율이 높습니다. `id_31`에 대해서도 같은 작업을 반복해 보겠습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `id_31` 그려보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "거래는 또한 Chrome 62.0, Chrome 62.0 for Android, mobile Safari 11.0 브라우저 순으로 이루어졌습니다. 이제 브라우저별 사기율도 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id.groupby('id_31') \\\n",
    "    .mean()['isFraud'] \\\n",
    "    .sort_values() \\\n",
    "    .plot(kind='barh',\n",
    "          figsize=(15, 45),\n",
    "          title='Percentage of Fraud by Browser Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "icedragon(Firefox 기반 오픈 소스 웹 브라우저)가 제일 사기를 당할 확률이 높았고, 그 뒤를 이어 모질라/파이어폭스가 잇고 있습니다. 크롬 브라우저의 경우 버전이 낮을수록 사기 거래를 당하기 쉬웠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `id_33` 그려보기\n",
    "`id_33`은 사용자의 기기 해상도로 사기 거래와 관련이 없어 보일 수 있습니다. 그러나 해상도가 낮을수록 사용자 기기의 성능이 낮고, 그에 따라 낮은 버전의 프로그램을 사용할 것이라는 생각이 들었습니다. 별 의미가 없어 보일 수 있지만 `id_33`에 대해서도 isFraud에 대한 비율을 비교해 보도록 하겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id.groupby('id_33').mean()['isFraud'].sort_values()\n",
    "group_id.sort_values('id_33', ascending=False).head(20).plot(kind='barh', \\\n",
    "                     figsize=(15, 75), title='Percentage of Fraud by Resolution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 사용량 확인하기\n",
    "!pip install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 해제\n",
    "import gc\n",
    "\n",
    "del [[train_tran, train_iden, test_tran, test_iden]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원하는 feature의 column만 뽑아 새로운 DF 구성하기\n",
    "\n",
    "위에서 열심히 진행한 EDA 과정을 통해 아래의 features를 뽑았습니다. \n",
    "\n",
    "* from `train_transaction.csv`\n",
    "    - TransactionAMT\n",
    "    - ProductCD\n",
    "    - card1~card6 \n",
    "    - P_emaildomain과 R_emaildomain feature\n",
    "    - M1 ~ M9 / isFraud\n",
    "* from `train_identity.csv`\n",
    "    - DeviceType, DeviceInfo\n",
    "    - id_30 , id_31, id_33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원하는 feature의 열들만 뽑아 새로운 DF로 구성합니다. \n",
    "cols= ['isFraud','TransactionDT','TransactionAmt','ProductCD', 'P_emaildomain', 'R_emaildomain']\n",
    "cards_cols= ['card1', 'card2', 'card3','card4','card5', 'card6']\n",
    "train[cols].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder 학습하기\n",
    "- WIP(non-fraud data로 학습해야 함.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import collections\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
    "                             roc_curve, recall_score, classification_report, f1_score)\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "                            \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable as V\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from bokeh.plotting import figure, output_notebook, show, ColumnDataSource\n",
    "from bokeh.models import HoverTool, NumeralTickFormatter\n",
    "from bokeh.palettes import Set3_12\n",
    "from bokeh.transform import jitter\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training epochs\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv(os.path.join(dataset_dir, 'train_transaction.csv'), index_col='TransactionID')\n",
    "train_identity = pd.read_csv(os.path.join(dataset_dir, 'train_identity.csv'), index_col='TransactionID')\n",
    "test_transaction = pd.read_csv(os.path.join(dataset_dir, 'test_transaction.csv'), , index_col='TransactionID')\n",
    "test_identity = pd.read_csv(os.path.join(dataset_dir, 'test_identity.csv'), index_col='TransactionID')\n",
    "sample_submission = pd.read_csv(os.path.join(dataset_dir, 'sample_submission.csv'), index_col='TransactionID')\n",
    "\n",
    "train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n",
    "test = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns(to drop NaN values) and Standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "def dropper(column_name, train, test):\n",
    "    train = train.drop(column_name, axis=1)\n",
    "    test = test.drop(column_name, axis=1)\n",
    "    return train, test\n",
    "\n",
    "del_columns = ['TransactionDT']\n",
    "for col in del_columns:\n",
    "    train, test = dropper(col, train, test)\n",
    "\n",
    "def scaler(scl, column_name, data):\n",
    "    data[column_name] = scl.fit_transform(data[column_name].values.reshape(-1,1))\n",
    "    return data\n",
    "\n",
    "scl_columns = ['TransactionAmt', 'card1', 'card3', 'card5', 'addr1', 'addr2']\n",
    "for col in scl_columns:\n",
    "    train = scaler(StandardScaler(), col, train)\n",
    "    test = scaler(StandardScaler(), col, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#TODO: Learning should be done by using non fraud data\n",
    "train = train[train['isFraud'] == 0]\n",
    "train_fraud = train[train['isFraud'] == 1].copy()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build AutoEncoder\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['isFraud'].copy()\n",
    "del train_transaction, train_identity, test_transaction, test_identity\n",
    "\n",
    "# Drop target\n",
    "X_train = train.drop('isFraud', axis=1)\n",
    "#X_train_fraud = train_fraud.drop('isFraud', axis=1)\n",
    "X_test = test.copy()\n",
    "\n",
    "del train, test\n",
    "    \n",
    "# TODO: change methods\n",
    "# Fill in NaNs\n",
    "X_train = X_train.fillna(-999)\n",
    "#X_train_fraud = X_train_fraud.fillna(-999)\n",
    "X_test = X_test.fillna(-999)\n",
    "\n",
    "# TODO: change to Label Count Endocing\n",
    "# Label Encoding\n",
    "for f in X_train.columns:\n",
    "    if X_train[f].dtype=='object' or X_test[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(X_train[f].values) + list(X_test[f].values)) #+ list(X_train_fraud[f].values))\n",
    "        X_train[f] = lbl.transform(list(X_train[f].values))\n",
    "        #X_train_fraud[f] = lbl.transform(list(X_train_fraud[f].values)) \n",
    "        X_test[f] = lbl.transform(list(X_test[f].values)) \n",
    "        \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.head())\n",
    "#print(X_train_fraud.head())\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    params:\n",
    "        data : data desired to be split\n",
    "        ratio : validation ratio for split\n",
    "        \n",
    "    output:\n",
    "        train_data, validation_data\n",
    "\"\"\"\n",
    "\n",
    "def splitter(data, ratio=0.2):\n",
    "    num = int(ratio*len(data))\n",
    "    return data[num:], data[:num]\n",
    "\n",
    "X_train, X_val = splitter(X_train)\n",
    "y_train, y_val = splitter(y_train)\n",
    "\n",
    "# Check number of data\n",
    "print(len(X_train), len(X_val), len(y_train), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr = torch.FloatTensor(X_train.values)\n",
    "xts = torch.FloatTensor(X_test.values)\n",
    "# X_val: validation data for isFraud == 0\n",
    "xvl = torch.FloatTensor(X_val.values) \n",
    "# X_train_fraud: validation data for isFraud == 1\n",
    "#xvt = torch.FloatTensor(X_train_fraud.values)\n",
    "\n",
    "xdl = DataLoader(xtr,batch_size=1000)\n",
    "tdl = DataLoader(xts,batch_size=1000)\n",
    "vdl = DataLoader(xvl,batch_size=1000)\n",
    "#fdl = DataLoader(xvt,batch_size=1000)\n",
    "\n",
    "print(len(X_train.values), len(X_test.values), len(X_val.values)) #, len(X_train_fraud))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build AE class\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, length):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(length,20)\n",
    "        self.lin2 = nn.Linear(20,10)\n",
    "        self.lin7 = nn.Linear(10,20)\n",
    "        self.lin8 = nn.Linear(20,length)\n",
    "        \n",
    "        self.drop2 = nn.Dropout(0.05)\n",
    "        \n",
    "        self.lin1.weight.data.uniform_(-2,2)\n",
    "        self.lin2.weight.data.uniform_(-2,2)\n",
    "        self.lin7.weight.data.uniform_(-2,2)\n",
    "        self.lin8.weight.data.uniform_(-2,2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = F.tanh(self.lin1(data))\n",
    "        x = self.drop2(F.tanh(self.lin2(x)))\n",
    "        x = F.tanh(self.lin7(x))\n",
    "        x = self.lin8(x)\n",
    "        return x\n",
    "    \n",
    "def score(x):\n",
    "    y_pred = model(V(x))\n",
    "    x1 = V(x)\n",
    "    return loss(y_pred,x1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(len(X_train.columns))\n",
    "loss=nn.MSELoss()\n",
    "learning_rate = 1e-2\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)\n",
    "\n",
    "# Utilize a named tuple to keep track of scores at each epoch\n",
    "model_hist = collections.namedtuple('Model','epoch loss val_loss')\n",
    "model_loss = model_hist(epoch = [], loss = [], val_loss = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training routine\n",
    "\n",
    "def train(epochs, model, model_loss):\n",
    "    try: c = model_loss.epoch[-1]\n",
    "    except: c = 0\n",
    "    for epoch in tqdm_notebook(range(epochs),position=0, total = epochs):\n",
    "        losses=[]\n",
    "        dl = iter(xdl)\n",
    "        for t in range(len(dl)):\n",
    "            # Forward pass: compute predicted y and loss by passing x to the model.\n",
    "            xt = next(dl)\n",
    "            y_pred = model(V(xt))\n",
    "            \n",
    "            l = loss(y_pred,V(xt))\n",
    "            losses.append(l)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "            l.backward()\n",
    "\n",
    "            # Calling the step function on an Optimizer makes an update to its parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "        val_dl = iter(tdl)\n",
    "        val_scores = [score(next(val_dl)) for i in range(len(val_dl))]\n",
    "        \n",
    "        model_loss.epoch.append(c+epoch)\n",
    "        model_loss.loss.append(l.item())\n",
    "        model_loss.val_loss.append(np.mean(val_scores))\n",
    "        print(f'Epoch: {epoch}   Loss: {l.item():.4f}    Val_Loss: {np.mean(val_scores):.4f}')\n",
    "\n",
    "train(model=model, epochs=epochs, model_loss=model_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Loss/Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, epochs-1, epochs)\n",
    "print(model_loss.loss)\n",
    "print(model_loss.val_loss)\n",
    "print(x)\n",
    "plt.plot(x, model_loss.loss, label=\"loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, model_loss.val_loss, label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataloader and get predictions for each batch of the test set.\n",
    "p = iter(vdl)\n",
    "preds = np.vstack([model(V(next(p))).cpu().data.numpy() for i in range(len(p))])\n",
    "\n",
    "# Create a pandas DF that shows the Autoencoder MSE vs True Labels\n",
    "error_nonfraud = np.mean(np.power((X_val-preds),2), axis=1)\n",
    "\"\"\"\n",
    "p = iter(fdl)\n",
    "preds = np.vstack([model(V(next(p))).cpu().data.numpy() for i in range(len(p))])\n",
    "error_fraud = np.mean(np.power((X_train_fraud-preds),2), axis=1)\n",
    "\n",
    "pd.DataFrame(error_fraud)\n",
    "\"\"\"\n",
    "error_df = pd.DataFrame(data = {'error':error_nonfraud,'true':y_val})\n",
    "\n",
    "error_df.groupby('true')['error'].describe().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(error_df.true, error_df.error)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = {})'.format(roc_auc))\n",
    "plt.legend()\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = error_df[error_df['true'] == 0]\n",
    "threshold = temp_df['error'].mean() + temp_df['error'].std()\n",
    "print(f'Threshold: {threshold:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Recall F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [1 if e > threshold else 0 for e in error_df.error.values]\n",
    "print(classification_report(error_df.true.values,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting Precision Recall\n",
    "conf_matrix = confusion_matrix(error_df.true, y_pred)\n",
    "\n",
    "sns.set(font_scale = 1.2)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(conf_matrix, xticklabels=['Not Fraud','Fraud'], yticklabels=['Not Fraud','Fraud'], annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting Precision Recall for each thresholds\n",
    "# Changing the threshold from threshold_min to threshold_max.\n",
    "plt.figure(figsize=(12, 12))\n",
    "m = []\n",
    "threshold_min = threshold * 0.99\n",
    "threshold_max = threshold * 1.01\n",
    "\n",
    "for thresh in np.linspace(threshold_min, threshold_max):\n",
    "    y_pred = [1 if e > thresh else 0 for e in error_df.error.values]\n",
    "    conf_matrix = confusion_matrix(error_df.true, y_pred)\n",
    "    m.append((conf_matrix,thresh))\n",
    "    \n",
    "count = 0\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        plt.subplot2grid((3, 3), (i, j))\n",
    "        sns.heatmap(m[count][0], xticklabels=['Not Fraud','Fraud'], yticklabels=['Not Fraud','Fraud'], annot=True, fmt=\"d\");\n",
    "        plt.title(f\"Threshold - {m[count][1]:.3f}\")\n",
    "        plt.ylabel('True class')\n",
    "        plt.xlabel('Predicted class')\n",
    "        plt.tight_layout()\n",
    "        count += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataloader and get predictions for each batch of the test set.\n",
    "p = iter(tdl)\n",
    "preds = np.vstack([model(V(next(p))).cpu().data.numpy() for i in range(len(p))])\n",
    "\n",
    "# Create a pandas DF that shows the Autoencoder MSE vs True Labels\n",
    "error = np.mean(np.power((X_test-preds),2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalization(x):\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    x_norm = (x-x_min) / (x_max-x_min)\n",
    "    return x_norm\n",
    "\n",
    "# min max normalization\n",
    "#error_df = pd.DataFrame(data={'isFraud':min_max_normalization(error)})\n",
    "error_df = pd.DataFrame(data={'isFraud':error})\n",
    "\n",
    "print(\"Num data: \" + str(len(error_df)))\n",
    "print(\"Beyond threshold num data: \" + str(len(error_df[error_df['isFraud'] > threshold])))\n",
    "#error_df[error_df['isFraud'] > threshold]\n",
    "\n",
    "x_min = 3600000\n",
    "x_max = 4200000\n",
    "plt.hlines(threshold, x_min, x_max, \"black\")\n",
    "plt.plot(error_df, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = pd.DataFrame(data={'isFraud':min_max_normalization(error)})\n",
    "error_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['isFraud'] = error_df\n",
    "sample_submission.to_csv('simple_autoencoder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
